{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDwep1K8Erxl"
   },
   "source": [
    "**Project:** Data Minining Project for  X company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzIu-UWIDXHw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7-ii3uyI8KY"
   },
   "source": [
    "The CRISP-DM Framework\n",
    "\n",
    "\n",
    "The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology.\n",
    "* Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n",
    "\n",
    "* Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n",
    "\n",
    "* Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n",
    "\n",
    "* Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n",
    "*  Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n",
    "*  Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n",
    "\n",
    "[Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo7Ml7tMQOf"
   },
   "source": [
    "**Data Set**\n",
    "### The data is for company X which is trying to control attrition. \n",
    "### There are two sets of data: \"Existing employees\" and \"Employees who have left\". The following attributes are available for every employee.\n",
    "\n",
    "\n",
    "*   Satisfaction Level\n",
    "\n",
    "*   Last evaluation\n",
    "\n",
    "*   Number of projects\n",
    "\n",
    "*   Average monthly hours\n",
    "\n",
    "*   Time spent at the company\n",
    "*   Whether they have had a work accident\n",
    "\n",
    "\n",
    "*  Whether they have had a promotion in the last 5 years\n",
    "\n",
    "\n",
    "*   Departments (column sales)\n",
    "\n",
    "\n",
    "*   Salary\n",
    "\n",
    "\n",
    "*  Whether the employee has left\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjSj2A2sSph_"
   },
   "source": [
    "**Your Role**\n",
    " \n",
    "\n",
    "*   As data science team member X company asked you to answer this two questions.\n",
    "*  What type of employees is leaving? \n",
    "\n",
    "*   Determine which employees are prone to leave next.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajdEVA7LiBUp"
   },
   "source": [
    "Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "This step mostly focuses on understanding the Business in all the different aspects. It follows the below different steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Identify the goal and frame the business problem.\n",
    "* Prepare Analytical Goal i.e. what type of performance metric and loss function to use\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "*   Prepare Work Flow Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4MwiCYzj2_u"
   },
   "source": [
    "### Write the main objectives of this project in your words?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "STyLda45j1Mf"
   },
   "outputs": [],
   "source": [
    "main_objectives ='''studying the data in company x will have a lot of objectives.\n",
    "the first thing I want to mention the objective of studying, the data in company x is to discover \n",
    "insights from massive amount of data provided by company x. which is structured data to get solution that help \n",
    "the company x to shape or meet specific business needs and Goals.the second thing in this project is to study\n",
    "the data given by company x and to extract knowledge from a data set. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CuOlxLxKMOLI"
   },
   "outputs": [],
   "source": [
    "assert len(main_objectives) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(main_objectives) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXeNxlCkbaw"
   },
   "source": [
    "### Outline the different data analysis steps you will follow to carry out the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC-tl8sUksQq"
   },
   "outputs": [],
   "source": [
    "dm_outline = '''\n",
    "1.I will Define Questions\n",
    "2.I will Set Clear Measurement Priorities\n",
    "3.I will collect Data\n",
    "4.I will Analyze Data collected\n",
    "5.then I will Interpret Results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K1mWuDoksTk"
   },
   "outputs": [],
   "source": [
    "assert len(dm_outline) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(dm_outline) > 70 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmUDFG1wkzUy"
   },
   "source": [
    "### What metrics will you use to measure the performance of your data analysis model? \n",
    "Write the equations of the metrics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCNulojKk_BP"
   },
   "source": [
    "Precision = $\\frac{TP}{(TP + FP)}$\n",
    "\n",
    "Accuracy  = $\\frac{TP+TN}{total}$\n",
    "\n",
    "True Positive Rate = $\\frac{TP}{actual yes}$ \n",
    "\n",
    "False Positive Rate = $\\frac{FP}{actual no}$\n",
    "        \n",
    "True Negative Rate = $\\frac{TN}{actual no}$\n",
    "        \n",
    "Precision =$\\frac {TP}{predicted yes}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLS2YHoRk_EK"
   },
   "source": [
    "Why do you choose these metrics? minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSynT14KlPSJ"
   },
   "outputs": [],
   "source": [
    "why_metrics = '''Because The confusion matrix used to describe \n",
    "the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr-Mk0E8lPVJ"
   },
   "outputs": [],
   "source": [
    "assert len(why_metrics) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(why_metrics) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAo19Ip6lUtm"
   },
   "source": [
    "### How would you know if your data analysis work is a success or not?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HESsiXW5llX-"
   },
   "outputs": [],
   "source": [
    "how_success = '''To know how my Data analysis work is successful, \n",
    "I Will See my final Interpreted Result on Data analysis And if it is successful it is satisfactory,\n",
    "if not I will go back to see what happen to my Data analysis work and repeatedly,\n",
    "I will try to solve the problem.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdUoiMIOlmXq"
   },
   "outputs": [],
   "source": [
    "assert len(how_success) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQE6dqo6l1TZ"
   },
   "source": [
    "## What kind of challenges do you expect in your analysis?\n",
    "List at least 3 challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrAhBQhQl8Lh"
   },
   "outputs": [],
   "source": [
    "challenge_text = '''Many challenges may occur in each step of Data analysis. Some of these are:\n",
    " 1.the amount of data collected.\n",
    " 2.Collecting meaningful and real-time data\n",
    " 3.Inaccessible data \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EedHa-Pll8X7"
   },
   "outputs": [],
   "source": [
    "assert len(challenge_text) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcJ8M6uWDeSE"
   },
   "source": [
    "<h2>Using the processed twitter data from yesterday's challenge</h2>.\n",
    "\n",
    "\n",
    "- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n",
    "\n",
    "- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n",
    "\n",
    "- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n",
    "\n",
    "- Visualize The $\\textbf{score}$ column using piechart and barchart\n",
    "\n",
    "<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n",
    "\n",
    "* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n",
    "* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n",
    "* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n",
    "* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n",
    "\n",
    "* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n",
    "\n",
    "* Evaluate your model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "85WxmGNGDcBY"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'retweeted_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ea64c88fa7be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/covid19.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtweets_df_extractor\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mchdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweetDfExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtweets_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_df_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweet_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\10acad\\Twitter-Data-Analysis\\extract_dataframe.py\u001b[0m in \u001b[0;36mget_tweet_df\u001b[1;34m(self, save)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_lang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\10acad\\Twitter-Data-Analysis\\extract_dataframe.py\u001b[0m in \u001b[0;36mfind_full_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_full_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             text = [x ['retweeted_status']['extended_tweet']['full_text']\n\u001b[0;32m     45\u001b[0m                 for x in self.tweets_list]\n",
      "\u001b[1;32m~\\Desktop\\10acad\\Twitter-Data-Analysis\\extract_dataframe.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_full_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             text = [x ['retweeted_status']['extended_tweet']['full_text']\n\u001b[0;32m     45\u001b[0m                 for x in self.tweets_list]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'retweeted_status'"
     ]
    }
   ],
   "source": [
    "import extract_dataframe as chdf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "_, tweet_list = chdf.read_json(\"./data/covid19.json\")\n",
    "tweets_df_extractor =chdf.TweetDfExtractor(tweet_list)\n",
    "tweets_df = tweets_df_extractor.get_tweet_df()\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5ad4b5c39444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleanTweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"original_text\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"polarity\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lang\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleanTweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcleanTweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lang\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"en\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lang\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "cleanTweet = tweets_df[[\"original_text\", \"polarity\", \"lang\"]]\n",
    "cleanTweet = cleanTweet[cleanTweet[\"lang\"] == \"en\"]\n",
    "cleanTweet.drop(\"lang\", axis=1, inplace=True)\n",
    "cleanTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_category(p):\n",
    "    \"\"\"\n",
    "    converts polarity into sentiment category\n",
    "    \"\"\"\n",
    "    if p > 0:\n",
    "        return \"positive\"\n",
    "    elif p < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleanTweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7dc36e6da1c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"polarity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_category\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleanTweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleanTweet' is not defined"
     ]
    }
   ],
   "source": [
    "cleanTweet[\"score\"] = cleanTweet[\"polarity\"].apply(text_category)\n",
    "cleanTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge_ Day2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
